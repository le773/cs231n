{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/jsxyhelu/DateSets/blob/master/DataAugmentation_eg2_%E6%95%88%E8%83%BD%E9%AA%8C%E8%AF%81.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "colab_type": "code",
    "id": "ABxMy4ObEXUW",
    "outputId": "0728aced-17a5-4cbb-e3cb-2ea59c85ab73"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n",
      "(10000, 32, 32, 3) (10000, 10)\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 5s 563us/step - loss: 1.8281 - acc: 0.3979 - val_loss: 1.3963 - val_acc: 0.5050\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 3s 352us/step - loss: 1.2127 - acc: 0.5729 - val_loss: 1.3446 - val_acc: 0.5230\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 3s 354us/step - loss: 0.9205 - acc: 0.6732 - val_loss: 1.3737 - val_acc: 0.5260\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 3s 353us/step - loss: 0.7135 - acc: 0.7488 - val_loss: 1.2685 - val_acc: 0.5620\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 3s 354us/step - loss: 0.5284 - acc: 0.8229 - val_loss: 1.1690 - val_acc: 0.6100\n",
      "10000/10000 [==============================] - 2s 158us/step\n",
      "Loss:  1.2000079774856567\n",
      "Accuracy:  0.5939\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.layers.core import Dense, Flatten, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.utils import generic_utils\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "def preprocess_data(x):\n",
    "    x /= 255\n",
    "    x -= 0.5\n",
    "    x *= 2\n",
    "    return x\n",
    "\n",
    "# 预处理\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "x_train = preprocess_data(x_train)\n",
    "x_test = preprocess_data(x_test)\n",
    "\n",
    "# one-hot encoding\n",
    "n_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "# 取 20% 的训练数据\n",
    "x_train_part = x_train[:10000]\n",
    "y_train_part = y_train[:10000]\n",
    "\n",
    "print(x_train_part.shape, y_train_part.shape)\n",
    "\n",
    "# 建立一个简单的卷积神经网络,序贯结构\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), input_shape=(32,32,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(scale=False, center=False))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization(scale=False, center=False))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# 训练参数\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "#epochs = 2\n",
    "#cifar-10 20%数据,训练结果\n",
    "model = build_model()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train_part, y_train_part, epochs=epochs, batch_size=batch_size, verbose=1, validation_split=0.1)\n",
    "\n",
    "loss, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Loss: ', loss)\n",
    "print('Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cifar-10 20%数据 + Data Augmentation.训练结果\n",
    "# 设置生成参数\n",
    "img_generator = ImageDataGenerator(\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    zoom_range = 0.2\n",
    "    )\n",
    "model_2 = build_model()\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v4DZMrYJKp3L"
   },
   "source": [
    "自定义ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "colab_type": "code",
    "id": "Qrsp4o6YKoPm",
    "outputId": "d53fad4d-9559-47ae-a29e-21b52e808ae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training...\n",
      "10000/10000 [==============================] - 8s 846us/step - train loss: 2.0566 - train acc: 0.3071\n",
      "Epoch 1\n",
      "Training...\n",
      "10000/10000 [==============================] - 7s 719us/step - train loss: 1.7397 - train acc: 0.3799\n",
      "Epoch 2\n",
      "Training...\n",
      "10000/10000 [==============================] - 7s 720us/step - train loss: 1.6284 - train acc: 0.4170 6s - train loss: 1.6095 - train  - ETA: 6s - train loss: 1.6539 - ET\n",
      "Epoch 3\n",
      "Training...\n",
      "10000/10000 [==============================] - 7s 716us/step - train loss: 1.5622 - train acc: 0.4396 5s - train loss: 1.5611 -  - ETA\n",
      "Epoch 4\n",
      "Training...\n",
      "10000/10000 [==============================] - 7s 720us/step - train loss: 1.4979 - train acc: 0.4656 0s - train loss: 1.4945 - train a\n",
      "10000/10000 [==============================] - 2s 218us/step\n",
      "Loss:  1.4424572896957397\n",
      "Accuracy:  0.5056\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "for e in range(epochs):\n",
    "    print('Epoch', e)\n",
    "    print('Training...')\n",
    "    progbar = generic_utils.Progbar(x_train_part.shape[0])\n",
    "    batches = 0\n",
    "\n",
    "    for x_batch, y_batch in img_generator.flow(x_train_part, y_train_part, batch_size=batch_size, shuffle=True):\n",
    "        loss,train_acc = model_2.train_on_batch(x_batch, y_batch)\n",
    "        batches += x_batch.shape[0]\n",
    "        if batches > x_train_part.shape[0]:\n",
    "            break\n",
    "        progbar.add(x_batch.shape[0], values=[('train loss', loss),('train acc', train_acc)])\n",
    "loss, acc = model_2.evaluate(x_test, y_test, batch_size=32)\n",
    "print('Loss: ', loss)\n",
    "print('Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###最后，我尝试采用文档中提示方法\n",
    "img_generator.fit(x_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 1.3042 - acc: 0.5303\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 1.1199 - acc: 0.5992\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 1.0211 - acc: 0.6369\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.9599 - acc: 0.6588\n",
      "Epoch 5/5\n",
      " 587/1000 [================>.............] - ETA: 21s - loss: 0.9255 - acc: 0.6715"
     ]
    }
   ],
   "source": [
    "# fits the model_2 on batches with real-time data augmentation:\n",
    "# ImageDataGenerator.flow 将会返回一个生成器，这个生成器用来扩充数据，每次都会产生batch_size个样本。\n",
    "model_2.fit_generator(img_generator.flow(x_train_part, y_train_part, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(x_train_part)//10, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score trained model.\n",
    "scores = model_2.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DataAugmentation_eg2_效能验证.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
